{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras U-Net starter - LB 0.277.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "0w7pxR_uyONJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "안녕하세요! 이번 커널은 케라스 기반의 신경망을 이용하여 핵을 분할(Segment)하는 방법을 보여줍니다.\n",
        "\n",
        "사용되는 아키텍처는 영상 분할 문제에서 매우 일반적이게 사용되는 일명 U-Net이란 모델입니다. 이 모델은 소규모 데이터셋에서도 잘 작동하는 경향이 있는 것 같습니다.\n",
        "\n",
        "우리가 필요한 모든 것을 import하면서 시작해봅시다."
      ]
    },
    {
      "metadata": {
        "id": "QhgIHnvgzF8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set some parameters\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "TRAIN_PATH = '../input/stage1_train/'\n",
        "TEST_PATH = '../input/stage1_test/'\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPIon9TIzHEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get train and test IDs\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GB7e2uYOzIIf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get the data\n",
        "\n",
        "먼저 모든 이미지와 관련된 마스크(mask)들을 가져옵니다. 트레이닝 이미지와 테스트 이미지를 관리하기 위해서 다운 샘플링 하지만, 예측된 마스크를 업샘플링하고 나중에 올바른 run-length 인코딩을 만들려면 테스트 이미지의 원래 사이즈를 기록해둬야 합니다."
      ]
    },
    {
      "metadata": {
        "id": "fRT-3nuuz6m-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get and resize train images and masks\n",
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "    Y_train[n] = mask\n",
        "\n",
        "# Get and resize test images\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print('Getting and resizing test images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDSwgB68z8qv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "무작위로 이미지를 뽑아 연관된 마스크를 그려서 상태가 괜찮은지 봅시다."
      ]
    },
    {
      "metadata": {
        "id": "KKyvk2Jdz7xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(train_ids))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USG_zkzr0Ouu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "좋아 보입니다."
      ]
    },
    {
      "metadata": {
        "id": "KbG8dySx0Rsf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Metric 생성\n",
        "\n",
        "이제 Keras의 서로 다른 Intersection over union(IOU) 임계값 메트릭에 대해 mean average precision을 정의하려고 합니다.\n",
        "Tensorflow는 mean IOU metric을 가지고 있지만 여러 임계값에 걸친 평균을 기본적으로 지원하지 않으므로 이를 구현하고자 하였습니다.\n",
        "하지만 **이 구현이 옳은지는 잘 모르겠습니다.** 이를 확인하는데 도움이 될 만한 사항이 있으면 언제든지 환영합니다!\n",
        "\n",
        "업데이트 : 여기에 보고된 결과와 LB 결과 간의 차이가 매우 크기 때문에 이 구현이 정확하지는 않습니다. 어떻게 학습을 하든 시간에 따라서 값이 증가하는 것처럼 보입니다."
      ]
    },
    {
      "metadata": {
        "id": "shhO4PeC1lry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXInC7S21qdH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 신경망 구축 및 학습\n",
        "\n",
        "다음으로 U-net 모델을 구축합니다. U-Net: Convolutional Networks for Biomedical Image Segmentation(링크)에 기반을 두고 있고 Kaggle Ultrasound Nerve Segmentation competition의 repo와 매우 유사합니다."
      ]
    },
    {
      "metadata": {
        "id": "X1s_JAep1mGw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
      ]
    },
    {
      "metadata": {
        "id": "BbOkO3ME2B_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9savdS32FOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "업데이트: ELU 단위로 변경, dropout 추가\n",
        "\n",
        "다음으로, 0.1 validation 분할을 사용하여 학습 데이터에 모델을 fit 합니다. 데이터가 거의 없기 때문에 작은 배치 사이즈를 사용합니다. 모델을 교육할 때는 checkpoint와 early stopping을 사용하는 것이 좋습니다.\n",
        "좀 더 재현할 수 있도록 여기서 하지는 않겠습니다.(결과가 매우 바뀔 것입니다) 10 epoch 동안 학습해 보겠습니다. Kaggle 커널에서 현재 매개 변수를 사용하는 데 10분 정도 걸립니다. \n",
        "\n",
        "업데이트: early stopping과 checkpoint 추가, 30 epoch으로 변경"
      ]
    },
    {
      "metadata": {
        "id": "Kr3ektgR2ErA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
        "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
        "                    callbacks=[earlystopper, checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWG3UkCh4CpY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "좋습니다. Loss는 약간 불규칙(erratic)한 것 같습니다. 모델 구조와 매개 변수를 개선하는 것은 직접 해보세요"
      ]
    },
    {
      "metadata": {
        "id": "yOPmN8wZ4u0o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 예측하기\n",
        "\n",
        "테스트셋, 검증셋, 트레인셋(상태 체크)으로 예측을 해봅니다. early stopping과 check point를 사용하는 경우 저장된 모델 중 가장 좋은 모델을 로드해야 합니다. "
      ]
    },
    {
      "metadata": {
        "id": "u1Qyvb-Y4CFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predict on train, val and test\n",
        "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in range(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
        "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
        "                                       mode='constant', preserve_range=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcnJ8OsR5UUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0dG7agu5Vmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 모델은 학습 데이터에 잘 예측합니다. 여기에서도 분명히 개선의 여지가 많지만  괜찮은 출발인 듯 합니다. 검증 데이터에서는 어떤가요?"
      ]
    },
    {
      "metadata": {
        "id": "Tua0Wz2N55jY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kC4ozN2W5724",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "너무 안좋지는 않지만 훈련과 조정이 더 필요해 보입니다.\n",
        "\n",
        "# 결과 인코딩 및 제출\n",
        "\n",
        "이제 결과를 제출해야 할 때입니다.  여기선  https://www.kaggle.com/rakhlin/fast-run-length-encoding-python에서의 run-length 인코딩 구현을 이용했습니다."
      ]
    },
    {
      "metadata": {
        "id": "2h7e7dge6r14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GC6IUIWj6tiB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "테스트 IDs를 반복하고 skimage로 식별된 각 분리된 마스크의 run-length 인코딩을 만듭니다."
      ]
    },
    {
      "metadata": {
        "id": "3i38fq-MKNKd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "84DUddks6_rA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_test_ids = []\n",
        "rles = []\n",
        "for n, id_ in enumerate(test_ids):\n",
        "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
        "    rles.extend(rle)\n",
        "    new_test_ids.extend([id_] * len(rle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRNj91-E7BBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "... 그리고 마침내 제출을 합니다."
      ]
    },
    {
      "metadata": {
        "id": "ZAeF1RNb7ErY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create submission DataFrame\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = new_test_ids\n",
        "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "sub.to_csv('sub-dsbowl2018-1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nucKLSw7Gd5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "0.233 LB 점을 받았다. 이 notebook version 2와 같다. 신경망 결과는 매우 불규칙하고 실행마다 차이가 있을 수 있다는 점을 알아줬으면 한다. (Version 3 결과는 더 안좋다.) Version 7은 0.277 점이다.\n",
        "\n",
        "몇몇 파라미터를 변경하고 아키텍처를 약간 수정하고 early stopping을 하고 더 길게 학습시킨다면 쉽게 결과를 안정화 시키고 결과를 개선시킬 수 있습니다. \n",
        "\n",
        "LB score history:\n",
        "\n",
        "Version 7 : 0.277 LB"
      ]
    }
  ]
}
