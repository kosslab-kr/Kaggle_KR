{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbf2ff22-712b-4fc2-8687-99caa9bf07d8",
    "_uuid": "f57e59e8589cb94001d8673fb737a4e0d96852bd",
    "collapsed": true
   },
   "source": [
    "이 Python 3 environment는 분석에 유용한 여러 libraires들을 이용합니다.\n",
    "이 environment는 kaggle/python docker image로 만들어져 있습니다. : https://github.com/kaggle/docker-python\n",
    "\n",
    "일단 먼저 예시로 몇가지 유용한 packages들을 소개드리겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra (선형대수학)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) (데이터 처리, CSV file의 I/O)\n",
    "\n",
    "# Input data files는 \"../input/\" directory에 있습니다.\n",
    "# 이것을 실행시키면 (run을 누르거나, Shift+Enter를 누르세요) input directory에 있는 file들을 보여줄 것입니다.\n",
    "# 그리고 현재 directory에 write한 모든 results들은 output 형태로 저장될 것입니다.\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2805f6da-0df3-41f1-977a-547dac26a11f",
    "_uuid": "113b5b8f58952300f5a35a3999788e2d076beeab"
   },
   "source": [
    "이 kernel은 Keras를 이용해 CNN을 구현하고 싶어하는 초심자들을 위한 것입니다. 이 kernel과 함께라면, 당신은 좋은 점수를 받을 수 있고, Keras에 대해서도 배울 수 있습니다.\n",
    "Keras는 model을 initialize하고 우리가 원하는 layer를 쌓아갈 수 있는 간단한 frameworks 입니다. Deep neural networks를 아주 쉽게 만들 수 있게 도와주죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "train = pd.read_json(\"../input/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"../input/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e178779f-0698-47cd-9be5-50f9c9590089",
    "_uuid": "f5b6c2ba24e6bf5726f8551cdeeeaf931184c2bc"
   },
   "source": [
    "### 데이터에 대한 기본 설명\n",
    "\n",
    "Sentinel 인공위성은 지구에서 680Km 떨어진 지점에 위치해 있습니다. 특정 입사각에서 pulses of signal들을 보낸 후, 돌아오는 신호를 기록합니다. 반사(산란)되어 되돌아온 신호는  \"backscatter\"라고 부릅니다. 우리에게 주어진 데이터는 backscatter 데이터입니다. 일반적인 backscatter 형태를 띄는데, 그 형태는 다음과 같습니다 : \n",
    "\n",
    "$σo (dB) = βo (dB) + 10log10 [sin(ip) / sin (ic)] $\n",
    "\n",
    "1. ip = 특정 pixel에서의 입사각\n",
    "2. ic = 이미지 중심에서의 입사각\n",
    "3. K = 상수\n",
    "\n",
    "우리는 이 $σo$ 값을 갖고 있습니다.\n",
    "\n",
    "### $σo$의 특징\n",
    "기본적으로 $σo$는 signal이 산란된 표면에 따라 다릅니다. 예를 들어, 어떠한 입사각에 대해 다양한 표면의 종류에 따라 데이터를 뽑아 보겠습니다. 데이터를 보면, 표면의 종류에 따라(Water, Settlements, Agriculture, Barren) 다른 값을 나타내는 것을 볼 수 있습니다.\n",
    "\n",
    "*             WATER...........           SETTLEMENTS........           AGRICULTURE...........          BARREN........\n",
    "\n",
    "1.**HH:**     -27.001   ................                     2.70252       .................                -12.7952        ................    -17.25790909\n",
    "\n",
    "2.**HV: **      -28.035      ................            -20.2665             ..................          -21.4471       .................     -20.019\n",
    "\n",
    "배에서 산란되어 되돌아온 signal의 data는 나와있지 않지만, 배와 얼음은 다른 물체이기 때문에 둘의 값은 완전히 달라야 할 것입니다. 우리는 이것을 이용해 배와 얼음을 구분할 수 있을 것입니다.\n",
    "\n",
    "### HH와 HV는 무엇입니까?\n",
    "이 Sentinel 인공위성은 RISTSAT 인공위성 (인도의 원격탐사 인공위성)과 같습니다. 이들은 pulses of signal을 보낼 때, 수평으로 편광(H polarization)된 signal을 보냅니다. **따라서 signal에 수직 성분(V polarization)은 포함되어 있지 않습니다.**.  보낸 H-pings(H poloarized 된 signal)들이 물체에 부딪히게 되면, 산란되어 편광상태가 달라지게 됩니다. 따라서 수평 성분(H) 뿐이었던 signal이 수평 성분(H)과 수직 성분(V)의 합(HH or HV)으로 반환됩니다.\n",
    "\n",
    "그런데 HH, HV Signal은 있는데 왜 VV Signal은 없을까요? 수평으로 편광(H polarization)된 signal은 절대 VV signal이 될 수 없기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature 만들기\n",
    "그럼 이제 feature를 봅시다. 우리는 주어진 HH, HV data를 보통 CNN에서 사용되는 RGB 즉 3-channel 데이터처럼 만들 것 입니다. 3-channel 데이터를 만들기 위해, HH, HV, 그리고 HH-HV의 평균값을 3rd channel으로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 데이터를 만듭니다.\n",
    "# HH, HV, HH와 HV의 평균 총 3개의 band를 만듭니다. \n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빙산을 봅시다\n",
    "#Take a look at a iceberg\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "def plotmy3d(c, name):\n",
    "    print(c.shape)\n",
    "    data = [\n",
    "        go.Surface(\n",
    "            z=c\n",
    "        )\n",
    "    ]\n",
    "    layout = go.Layout(\n",
    "        title=name,\n",
    "        autosize=False,\n",
    "        width=700,\n",
    "        height=700,\n",
    "        margin=dict(\n",
    "            l=65,\n",
    "            r=50,\n",
    "            b=65,\n",
    "            t=90\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)\n",
    "plotmy3d(X_band_1[12,:,:], 'iceberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd7ea3c1-f039-445e-b5da-adfb608930d7",
    "_uuid": "1c65412c80ff504df19d55aa14093ebcd1028e6a"
   },
   "source": [
    "데이터를 plot해보니 멋진 빙산이 보이네요. 레이더 데이터를 이용해서 빙산을 만들게 되면, 여기서 보이는 것과 같은 산 모양을 나타낼 것입니다. 왜냐하면, 이것은 실제 이미지 데이터가 아니라, 레이더에서 산란된 데이터를 갖고 만든 데이터이기 때문에 뾰족한 봉우리 모양을 갖도록 왜곡됩니다. 그리고 배의 모양은 점, 혹은 연장된 점으로 왜곡될 것입니다. 어쨋거나 우리는 여기서 빙산과 배의 구조적인 차이점이 있음을 알 수 있고, CNN을 이용해 이 차이점을 바탕으로 빙산과 배를 구분하도록 할 것입니다. 우리가 레이더로부터 얻은 backscatter를 이용하여 합성 사진을 만들 수 있다면, 많은 도움이 될 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotmy3d(X_band_1[14,:,:], 'Ship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e2a6f33-992a-435e-be65-5ee614e6f7ba",
    "_uuid": "f907f993a1c63f4519872ecb381021c1a0dce2ca"
   },
   "source": [
    "이것은 배입니다, 연장되어 있는 점같이 생겼네요. 그런데 이 레이더 데이터만 갖고 배 모양을 시각화하기엔 해상도가 부족합니다. 그리고 그것을 도와주기위해 CNN이 존재합니다. 배-빙산 classification과 관련된 참고해 볼만한 논문이 있습니다.\n",
    "http://elib.dlr.de/99079/2/2016_BENTES_Frost_Velotto_Tings_EUSAR_FP.pdf\n",
    "그런데 그들은 훨씬 좋은 해상도를 갖고 있는 데이터를 사용하였기 때문에, 그들이 이용한 CNN은 여기에 맞지 않을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c0c41e0-b95e-4129-a95e-06cd6808553d",
    "_uuid": "906b685c8ab2b91b3b9e4baffb65ad1c1aa028c3"
   },
   "source": [
    "### CNN Layer 만들기\n",
    "자 이제 Keras로 CNN을 만들어 봅시다. Keras는 다른 framework보다 훨씬 좋습니다. 아마 당신도 분명히 Keras를 좋아할 거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without denoising, core features.\n",
    "import os\n",
    "gmodel=getModel()\n",
    "gmodel.fit(X_train_cv, y_train_cv,\n",
    "          batch_size=24,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "923850b1-707e-41e7-bdcb-b5d0633fb12f",
    "_uuid": "04da75db4d60b76ae357503ea1178808e1026b56"
   },
   "source": [
    "이 LB 점수는 조금 다르게 나올 수도 있는데, 저는 0.210를 받았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.load_weights(filepath=file_path)\n",
    "score = gmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "predicted_test=gmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5140949-c867-43fd-baba-49e57bec44cf",
    "_uuid": "741f9696d91da6af29266fb199a6c2fb80d26dfe",
    "collapsed": true
   },
   "source": [
    "### 결론\n",
    "점수를 올리기 위해 추가적으로 Speckle filtering, Indicence angle normalization, 그리고 다른 preprocessing을 사용해 보았는데 잘 작동하지 않았습니다. 원한다면 그것들을 해보는 것도 괜찮겠지만, 저같은 경우 좋은 결과는 나오지 않았습니다.\n",
    "\n",
    "어짜피 이 kernel을 이용한다고 해서 상위 10명 안에 들지는 못할것이니, 좋은 정보를 하나 드리겠습니다. Test dataset에 8000개의 이미지가 존재하는데, 그것을 활용해 보세요. pseudo labeling을 해서 성능을 높혀볼 수 있을 것입니다. 관련 링크 첨부합니다:\n",
    "https://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b\n",
    "\n",
    "이 kernel이 도움이 되었다면 Upvote해주세요 :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
