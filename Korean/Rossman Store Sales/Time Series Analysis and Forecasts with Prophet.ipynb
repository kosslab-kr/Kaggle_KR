{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컴피티션 소개\n",
    "\n",
    "로스만은 7개의 유럽국가에서 3,000개가 넘는 드러그 스토어를 운영하는 회사입니다. 또한, 최근 로스만 매장 관리자는 최대 6주의 일간 판매량을 예측하는 업무를 진행하고 있습니다. 매장의 판매량은 홍보를 포함하여 시장 경쟁, 학교 또는 지역의 휴일, 계절, 지역 등 많은 요인에 의해 영향을 받습니다. 수천 명의 관리자들은 자신들만의 배경 지식을 토대로 판매량을 예측하며, 매우 다양한 결과를 얻고 있습니다.\n",
    "\n",
    "로스만은 독일 전체에 있는 1,115개의 매장 데이터를 바탕으로 다음 6주간의 일간 판매량을 예측하는 문제를 제시했습니다. 정확한 판매량 예측은 매장 관리자들이 효율적으로 직원들의 일정을 관리하고, 생산선 증가 및 동기 부여 관점에서 중요하게 여겨집니다. 우리가 로스만의 판매량을 확고하게 예측하는 모델 생성을 도와줌으로써 매장 관리자들이 더 중요한 것에 집중할 수 있도록 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시계열 분석과 Prophet 라이브러리를 사용한 예측 \n",
    "\n",
    "** 목표: **\n",
    "asdasdasdasdas\n",
    "- 데이터를 탐험해보자. (ECDF 라이브러리를 사용해 결측치를 다뤄보자.)\n",
    "- 매장 형태와 매장 활동의 상관관계 분석을 해보자.\n",
    "- 시계열 분석을 확장해서 수행해보자. (seasonal_decompose 라이브러리, 경향, 자기 상관성을 고려해보자.)\n",
    "- Prophet 라이브러리를 사용해 다음 6주간의 판매량을 예측해보자.(Facebook의 방법론이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ca6a26a-a225-44de-a28c-445dbb9395cf",
    "_uuid": "2afc7d05cfcbeeb1fb4a3d4916ad24be9cedef77"
   },
   "source": [
    "# Time Series Analysis and Forecasting with Prophet\n",
    "\n",
    " **Goal:** \n",
    "\n",
    "- Explore the data (ECDF, handle missing values etc).\n",
    "- Analysis per store type and correlational analysis of stores activity.\n",
    "- Perform extensive Time Series Analysis (seasonal decomposition, trends, autocorrelation).\n",
    "- Predict next 6 weeks of sales using Prophet (Facebook methodology)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 커널은 시계열 분석에 초점을 두고 있습니다. 중요한 주제는 아직 밝혀지지 않았고, 다음 6주간의 일간 매출을 예측하기 위해 최근 Facebook이 소개한 Prophet이라는 새로운 방법을 사용하려고 합니다. 이 방법론은 휴일에 대해 모델링을 할 수 있는 좋은 특징을 가지고 있습니다. 마지막으로 끝 부분에 Seasonal ARIMA and Prophet의 장단점에 대해 논의하고자 합니다.\n",
    "\n",
    "항상 하던대로 데이터를 살펴보고자 합니다. 데이터의 패턴과 존재하는 경향을 찾아내기 위해 여러가지 척도를 사용할 것이다. 추후의 분석을 위해서 기반을 탄탄하게 다져봅시다.\n",
    "\n",
    "**스압주의**:\n",
    "\n",
    "\"스압주의\"지만 스크롤 값을 합니다. 또한 많은 시간이 필요하겠지만, 해당 커널의 이전 버전이나 풀 버전을 [이곳](https://github.com/elena-petrova/rossmann_TSA_forecasts) 에서 확인할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c1a12388-2437-443a-b7ad-f916238bd0e5",
    "_uuid": "c770837098683cad4c93dfd51ec619256f5fa871"
   },
   "source": [
    "This notebook mainly focuses on the *Time Series Analysis*. An important topic yet not covered. I use then *new methodology Prophet*, recently introduced by *Facebook,* to predict next 6 week of sales. This methodology has a cool feature of modeling for holidays. Finally, right at the end, I also discuss*advantages and drawbacks of forecasting with Seasonal ARIMA and Prophet.*\n",
    "\n",
    "As it usually goes, we start with the Exploratory Data Analysis of the main metrics revealing present trends and patterns in the data, giving a solid foundation for the further (causal) analysis. \n",
    "<br> \n",
    "<br>\n",
    "**WARNING**: \n",
    "\n",
    "It's a long read post but it's worth it. It might also need more time to run the script, but you can check out the full and *fast* version of the notebook on the [GitHub repository](https://github.com/elena-petrova/rossmann_TSA_forecasts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재밌게 보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba68b412-66ff-432d-9356-1e15cc9b2e78",
    "_execution_state": "idle",
    "_uuid": "d93687a3cfa592db7089bb3312a2ce56e220b7ee"
   },
   "source": [
    "Enjoy the reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b33c81c-f92e-4557-8277-81e225fc9a1d",
    "_uuid": "ca2249880400c77664cb49fc7d92273672a5cbf6"
   },
   "source": [
    "![rossmann][1]\n",
    "\n",
    "\n",
    "  [1]: https://kaggle2.blob.core.windows.net/competitions/kaggle/4594/media/rossmann_banner2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3afa1a34-f62c-42ec-8396-e77e56dbadbd",
    "_uuid": "c559ddee2294a923160c847bc0bca8f2b454f4f8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5a3b3b53-7757-403a-a1d2-8567d8869aaa",
    "_execution_state": "idle",
    "_uuid": "3b14af2f165220db8d2cb6e0684c25b59e03caa2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# loading packages\n",
    "# basic + dates \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # advanced vizs\n",
    "%matplotlib inline\n",
    "\n",
    "# statistics\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# prophet by Facebook\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "868c6aa5-865a-4386-bd67-5eb1704478f4",
    "_execution_state": "idle",
    "_uuid": "5a679719e8a8d9e3385459eb1f038d2255ae2a94"
   },
   "outputs": [],
   "source": [
    "# importing train data to learn\n",
    "train = pd.read_csv(\"../input/train.csv\", \n",
    "                    parse_dates = True, low_memory = False, index_col = 'Date')\n",
    "\n",
    "# additional store data\n",
    "store = pd.read_csv(\"../input/store.csv\", \n",
    "                    low_memory = False)\n",
    "# time series as indexes\n",
    "train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e6bd756-82a9-40b5-8cca-8f4a6fe36ee0",
    "_uuid": "649f9da4af596d880618bed9c67485a9b9c35c37"
   },
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4830f82b-fa4d-4070-ac54-b1d993dbecbf",
    "_uuid": "e36090f02a4a243a210b6df6f46372826a71d61c"
   },
   "source": [
    "In this first section we go through the train and store data, handle missing values and create new features for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e3b313a-c653-4af4-8d6f-5b3422a4eb4e",
    "_execution_state": "idle",
    "_uuid": "8e05ee04d06d431cdd8bac1d08c1ba3a1171f87b"
   },
   "outputs": [],
   "source": [
    "# first glance at the train set: head and tail\n",
    "print(\"In total: \", train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dffb7252-18e1-4923-9670-c08dfe2bcb9d",
    "_uuid": "230f569230fbfb28545ca465cff06f898f7f924f"
   },
   "source": [
    "##### Short description:\n",
    "- Sales: the turnover for any given day (target variable).\n",
    "- Customers: the number of customers on a given day.\n",
    "- Open: an indicator for whether the store was open: 0 = closed, 1 = open.\n",
    "- Promo: indicates whether a store is running a promo on that day.\n",
    "- StateHoliday: indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. \n",
    "- SchoolHoliday: indicates if the (Store, Date) was affected by the closure of public schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1185c5cb-cbeb-46c3-92d3-968946864adf",
    "_uuid": "47ccbc3bb09d565d6c0f9c49187ab7af2b416c55"
   },
   "source": [
    "We are dealing with time series data so it will probably serve us to extract dates for further analysis. We also have two likely correlated vaiables in the dataset, which can be combined into a new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "467b3abf-5989-479e-b225-db756e47555e",
    "_uuid": "ef2dff1b35a8b2659652c8f1ce00c9c3581da2e7"
   },
   "outputs": [],
   "source": [
    "# data extraction\n",
    "train['Year'] = train.index.year\n",
    "train['Month'] = train.index.month\n",
    "train['Day'] = train.index.day\n",
    "train['WeekOfYear'] = train.index.weekofyear\n",
    "\n",
    "# adding new variable\n",
    "train['SalePerCustomer'] = train['Sales']/train['Customers']\n",
    "train['SalePerCustomer'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "039fb816-6644-4494-a52a-79db3e5beab8",
    "_uuid": "ee4a0e393e3d8a406b229be42b85574c316c5083"
   },
   "source": [
    "On average customers spend about 9.50$ per day. Though there are days with Sales equal to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b086e424-d33d-43e7-940c-e7d5a0c61025",
    "_uuid": "a7b2a4d13c34397eb06e10914546f54d411ccf0d"
   },
   "source": [
    "### ECDF: empirical cumulative distribution function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "218c2f61-19c1-4050-8cb1-c9d8d41c3122",
    "_uuid": "06a03cce9c76bcc28021cd0264dbdfb719d7ed38"
   },
   "source": [
    "To get the first impression about continious variables in the data we can plot ECDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e43a9b1a-30ff-4d50-9080-8ef9cda5fdf7",
    "_uuid": "c37047a96382b99936d10a3920bf775700b0db03"
   },
   "outputs": [],
   "source": [
    "sns.set(style = \"ticks\")# to format into seaborn \n",
    "c = '#386B7F' # basic color for plots\n",
    "plt.figure(figsize = (12, 6))\n",
    "\n",
    "plt.subplot(311)\n",
    "cdf = ECDF(train['Sales'])\n",
    "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
    "plt.xlabel('Sales'); plt.ylabel('ECDF');\n",
    "\n",
    "# plot second ECDF  \n",
    "plt.subplot(312)\n",
    "cdf = ECDF(train['Customers'])\n",
    "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
    "plt.xlabel('Customers');\n",
    "\n",
    "# plot second ECDF  \n",
    "plt.subplot(313)\n",
    "cdf = ECDF(train['SalePerCustomer'])\n",
    "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
    "plt.xlabel('Sale per Customer');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "577dce58-3945-4561-9497-9e7e04049b89",
    "_uuid": "c8b0d6273c12db11e5e04993353fa6aad9cf0ec1"
   },
   "source": [
    "About 20% of data has zero amount of sales / customers that we need to deal with and almost 80% of time daily amount of sales was less than 1000. So what about zero sales, is it only due to the fact that the store is closed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f7c3ed93-31ae-4f3e-8bb4-3f2abb55f4b8",
    "_uuid": "28d33f9fc89c3c875acd17a9ccb601b915034ffd"
   },
   "source": [
    "### Missing values \n",
    "#### Closed stores and zero sales stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d659f57-0039-4291-ad2c-77828154c7dd",
    "_uuid": "9a9eb2c801a4e1584d21c17b597b9d24d01bbae6"
   },
   "outputs": [],
   "source": [
    "# closed stores\n",
    "train[(train.Open == 0) & (train.Sales == 0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0960522a-2fbd-4480-94c2-a819428b852c",
    "_uuid": "9c04d4e401ffebc8750e2695972c11d05a316c70"
   },
   "source": [
    "There're 172817 closed stores in the data. It is about 10% of the total amount of observations. To avoid any biased forecasts we will drop these values. \n",
    "\n",
    "What about opened stores with zero sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac085610-1679-495f-b7f5-7bc67240a983",
    "_uuid": "a8783c4d1422410bac5e08ae862d9497bb1ec3e8"
   },
   "outputs": [],
   "source": [
    "# opened stores with zero sales\n",
    "zero_sales = train[(train.Open != 0) & (train.Sales == 0)]\n",
    "print(\"In total: \", zero_sales.shape)\n",
    "zero_sales.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c54d654-080d-4762-bb89-7d3eaee57521",
    "_uuid": "12ac977ebc6fc68b056204a55482775926dff945"
   },
   "source": [
    "Interestingly enough, there are opened store with __no sales on working days__. There're only 54 days in the data, so we can assume that there were external factors involved, for example manifestations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "133a16e6-460c-44a2-89d3-0fa1319999fa",
    "_uuid": "36ce7f48f6c02866573f67a85be02cbef0e7a612",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Closed stores and days which didn't have any sales won't be counted into the forecasts.\")\n",
    "train = train[(train[\"Open\"] != 0) & (train['Sales'] != 0)]\n",
    "\n",
    "print(\"In total: \", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37265fa7-5e29-44d9-acb0-5515d52f0299",
    "_uuid": "486db76f21f026457b2509bb01bfd251783845a9"
   },
   "source": [
    "What about store information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "232cfcd1-3ecb-4a82-8ec4-1e39a762ec33",
    "_uuid": "61007f42d13f5d99d02522b803be24e3e367837e"
   },
   "outputs": [],
   "source": [
    "# additional information about the stores\n",
    "store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f2448d8c-34ba-4206-a921-9c5a7abde020",
    "_uuid": "aef2fe3bc4ff8347595fbdb8f39611274215a122"
   },
   "source": [
    "- Store: a unique Id for each store\n",
    "- StoreType: differentiates between 4 different store models: a, b, c, d\n",
    "- Assortment: describes an assortment level: a = basic, b = extra, c = extended\n",
    "- CompetitionDistance: distance in meters to the nearest competitor store\n",
    "- CompetitionOpenSince[Month/Year]: gives the approximate year and month of the time the nearest competitor was opened\n",
    "- Promo2: Promo2 is a continuing a promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "- Promo2Since[Year/Week]: describes the year and calendar week when the store started participating in Promo2\n",
    "- PromoInterval: describes the consecutive intervals Promo2 is started, naming the months the promotion is started. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5bc713f-4a1e-4ae0-9132-80a2a9a829d0",
    "_uuid": "1acb3a117d524b5ed6544bcae503d748ff41f6ed"
   },
   "outputs": [],
   "source": [
    "# missing values?\n",
    "store.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25a2875e-9bde-4c12-951c-c7c72ca6f655",
    "_uuid": "3d905023b0b5944d6907249ca3c08d9efba5ca43"
   },
   "source": [
    "We have few variables with missing values that we need to deal with. Let's start with the `CompetitionDistance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33602b69-1690-4db2-b224-422d68c7f788",
    "_uuid": "6b932d3e7089db078c1b52a8eb6079fe9e8f93ef"
   },
   "outputs": [],
   "source": [
    "# missing values in CompetitionDistance\n",
    "store[pd.isnull(store.CompetitionDistance)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9eb6694c-f930-48c1-aed8-e73afe94dabc",
    "_uuid": "6233f4fe6550fdfc8d5091efa197575ddb4df4d7"
   },
   "source": [
    "Apperently this information is simply missing from the data. No particular pattern observed. In this case, it makes a complete sense to replace NaN with the median values (which is twice less that the average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "727130aa-5538-4ae1-92ad-bd9edd83cf30",
    "_uuid": "556bbaeea0022573460de3aa1fded02108592cab"
   },
   "outputs": [],
   "source": [
    "# fill NaN with a median value (skewed distribuion)\n",
    "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e25e9d8-d695-4b43-975a-ff563e461a28",
    "_uuid": "7768fff72cd38e96d55c329f33449d86317ea986"
   },
   "source": [
    "Continuing further with missing data. What about `Promo2SinceWeek`? May it be that we observe unsusual data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cee66788-e322-49d8-a613-2c9a461e631a",
    "_uuid": "ab703f0c379978b9a0c5d9822005a6229a6e946c"
   },
   "outputs": [],
   "source": [
    "# no promo = no information about the promo?\n",
    "_ = store[pd.isnull(store.Promo2SinceWeek)]\n",
    "_[_.Promo2 != 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c92faa1-5c1c-4b7b-91db-e80e2defc7ec",
    "_uuid": "a5a2d06ab4a4576bcc17aae21646b777e3ade214"
   },
   "source": [
    "No, if there's no `Promo2` then there's no information about it. We can replace these values by zeros. The same goes for tha variables deducted from the competition, `CompetitionOpenSinceMonth` and `CompetitionOpenSinceYear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fc054e3d-498d-408c-a5d6-e3f85bdccaf7",
    "_uuid": "dd12ed8abd7ed251cec0062ab9f2042f8befc9e7"
   },
   "outputs": [],
   "source": [
    "# replace NA's by 0\n",
    "store.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2a7bcb45-ebe2-495e-88f8-58d7d9b8c13f",
    "_uuid": "81cd7d0c91bb7edcf2f21056171ec2b075586921"
   },
   "outputs": [],
   "source": [
    "print(\"Joining train set with an additional store information.\")\n",
    "\n",
    "# by specifying inner join we make sure that only those observations \n",
    "# that are present in both train and store sets are merged together\n",
    "train_store = pd.merge(train, store, how = 'inner', on = 'Store')\n",
    "\n",
    "print(\"In total: \", train_store.shape)\n",
    "train_store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee8f7083-17e5-4bde-8ba3-f8984f69db2e",
    "_uuid": "c8970b11d7cf26cdf221aa4efb2d5cbf38059cb0"
   },
   "source": [
    "### Store types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f48df70e-ae33-4781-b814-398a9f9930bf",
    "_uuid": "0ef10d82edadf2c2708027ebc656d5e5dc2fc0da"
   },
   "source": [
    "In this section we will closely look at different levels of `StoreType` and how the main metric `Sales` is distributed among them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6bbc4222-42f6-4014-9557-e9198376015c",
    "_uuid": "6baa0185e6ca348269e93315056bb9185551e770"
   },
   "outputs": [],
   "source": [
    "train_store.groupby('StoreType')['Sales'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "252a994a-4e08-43ac-b0be-fe110d780ac7",
    "_uuid": "8212db6d7833da3d9f42afaa0aa2d9ec10bfb1a5"
   },
   "source": [
    "`StoreType` B has the highest average of Sales among all others, however we have much less data for it. So let's print an overall sum of `Sales` and `Customers` to see which `StoreType` is the most selling and crowded one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8c90288-d1f2-4f2e-a894-b8ab187ff9bb",
    "_uuid": "5e9eebdc4a081f11b6fada77b46c6114e22eabc7"
   },
   "outputs": [],
   "source": [
    "train_store.groupby('StoreType')['Customers', 'Sales'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54df3ecf-28bb-4807-9b0d-a50a0906eedd",
    "_uuid": "874d7c509a8541c620f5edc69a92ff8f03b9f39c"
   },
   "source": [
    "Clearly stores of type A. `StoreType` D goes on the second place in both `Sales` and `Customers`.\n",
    "What about date periods? Seaborn's facet grid is the best tool for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6680fb46-3986-46d7-990a-66f03fc82ea7",
    "_uuid": "9677285bdd6595a4273c7d58573875d350ea0967"
   },
   "outputs": [],
   "source": [
    "# sales trends\n",
    "sns.factorplot(data = train_store, x = 'Month', y = \"Sales\", \n",
    "               col = 'StoreType', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               hue = 'StoreType',\n",
    "               row = 'Promo', # per promo in the store in rows\n",
    "               color = c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00fedbab-47c5-4098-b0f8-547e9d698a66",
    "_uuid": "4b6335f69bddb13716011644d2ca02392c1aeade"
   },
   "outputs": [],
   "source": [
    "# sales trends\n",
    "sns.factorplot(data = train_store, x = 'Month', y = \"Customers\", \n",
    "               col = 'StoreType', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               hue = 'StoreType',\n",
    "               row = 'Promo', # per promo in the store in rows\n",
    "               color = c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17cd2b7d-0e85-4cb5-b667-3d35862ae185",
    "_uuid": "07d7b866eb4feeda249fa3699fdffa64d2a52b51"
   },
   "source": [
    "All store types follow the same trend but at different scales depending on the presence of the (first) promotion `Promo` and `StoreType` itself (case for B).\n",
    "\n",
    "__Already at this point, we can see that Sales escalate towards Christmas holidays. But we'll talk about seasonalities and trends later in the Time Series Analysis section.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "17de03e5-f1c4-4391-9575-9090ac7075f1",
    "_uuid": "0940de0c939bc1994516c75f9cf271a2f3f922b2"
   },
   "outputs": [],
   "source": [
    "# sale per customer trends\n",
    "sns.factorplot(data = train_store, x = 'Month', y = \"SalePerCustomer\", \n",
    "               col = 'StoreType', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               hue = 'StoreType',\n",
    "               row = 'Promo', # per promo in the store in rows\n",
    "               color = c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2e13db0-608f-4d09-8014-54a7a38d490e",
    "_uuid": "083c6a3ee73e528d57a833660dd97255d655a39c"
   },
   "source": [
    "Aha! Eventhough the plots above showed `StoreType` B as the most selling and performant one, in reality it is not true. The highest `SalePerCustomer` amount is observed at the `StoreType` D, about 12€ with `Promo` and 10€ without. As for `StoreType` A and C it is about 9€. \n",
    "\n",
    "Low `SalePerCustomer` amount for `StoreType` B describes its Buyer Cart: there are a lot of people who shop essentially for \"small\" things (or in a little quantity). Plus we saw that overall this `StoreType` generated the least amount of sales and customers over the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8319e131-53a7-462b-955c-ca061d8b5738",
    "_uuid": "d7715f46f381622386d0d6bcf3571d83fa8f072f"
   },
   "outputs": [],
   "source": [
    "# customers\n",
    "sns.factorplot(data = train_store, x = 'Month', y = \"Sales\", \n",
    "               col = 'DayOfWeek', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               hue = 'StoreType',\n",
    "               row = 'StoreType', # per store type in rows\n",
    "               color = c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9e087df-f697-4ad3-bf08-cb8035635813",
    "_uuid": "ac6b7efdec4299f9b507f52ac99137c556698609"
   },
   "source": [
    "We see that stores of `StoreType` C are all closed on Sundays, whereas others are most of the time opened. Interestingly enough, stores of `StoreType` D are closed on Sundays only from October to December.\n",
    "\n",
    "Bt the way what are the stores which are opened on Sundays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e53e722-6a26-40b2-80dc-e25778730b8c",
    "_uuid": "b8d8927e537091debc913a03ce015fd7a88aaba6"
   },
   "outputs": [],
   "source": [
    "# stores which are opened on Sundays\n",
    "train_store[(train_store.Open == 1) & (train_store.DayOfWeek == 7)]['Store'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b21e83c0-ff98-441c-b242-08fbc38c2617",
    "_uuid": "088bc5998d6dcc46361b3fdb9bcbf39aec63a963"
   },
   "source": [
    "To complete our preliminary data analysis, we can add variables describing the period of time during which competition and promotion were opened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0d727532-55da-498f-9a6c-a650365b0a2e",
    "_uuid": "0aa951ce339281cbf9f7a141262b1adade4184bc"
   },
   "outputs": [],
   "source": [
    "# competition open time (in months)\n",
    "train_store['CompetitionOpen'] = 12 * (train_store.Year - train_store.CompetitionOpenSinceYear) + \\\n",
    "        (train_store.Month - train_store.CompetitionOpenSinceMonth)\n",
    "    \n",
    "# Promo open time\n",
    "train_store['PromoOpen'] = 12 * (train_store.Year - train_store.Promo2SinceYear) + \\\n",
    "        (train_store.WeekOfYear - train_store.Promo2SinceWeek) / 4.0\n",
    "\n",
    "# replace NA's by 0\n",
    "train_store.fillna(0, inplace = True)\n",
    "\n",
    "# average PromoOpen time and CompetitionOpen time per store type\n",
    "train_store.loc[:, ['StoreType', 'Sales', 'Customers', 'PromoOpen', 'CompetitionOpen']].groupby('StoreType').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "69f70f76-2f83-42a7-b46b-0ff992d18d9e",
    "_uuid": "6cd1bbac9504ba0bf4c34aa507d8584929067e82"
   },
   "source": [
    "The most selling and crowded `StoreType` A doesn't appear to be the one the most exposed to competitors. Instead it's a `StoreType` B, which also has the longest running period of promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d567f4a7-46ca-4881-bbd2-452f9ac7259d",
    "_uuid": "1468a1c2f2476c1175a9b711c250b188d496b842"
   },
   "source": [
    "### Correlational Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dfe6f12e-f432-4ced-a113-c30744a53213",
    "_uuid": "ce899f9f61a967dba176a76113d00aec8bd9b056"
   },
   "source": [
    "We are finished with adding new variables to the data, so now we can check the overall correlations by plotting the `seaborn` heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f53fef0-f709-4b5a-921b-021a78e25066",
    "_uuid": "4e7f2b0e3cc7d2eba98634872b359023db2d7a1f"
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix \n",
    "# exclude 'Open' variable\n",
    "corr_all = train_store.drop('Open', axis = 1).corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr_all, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize = (11, 9))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_all, mask = mask,\n",
    "            square = True, linewidths = .5, ax = ax, cmap = \"BuPu\")      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f20659d-608b-451e-9587-d59e0430905c",
    "_uuid": "d6cc9f79045d559581632a04700d48a8552ffdbf"
   },
   "source": [
    "As mentioned before, we have a strong positive correlation between the amount of Sales and Customers of a store. We can also observe a positive correlation between the fact that the store had a running promotion (`Promo` equal to 1) and amount of `Customers`. \n",
    "\n",
    "However, as soon as the store continues a consecutive promotion (`Promo2` equal to 1) the number of `Customers` and `Sales` seems to stay the same or even decrease, which is described by the pale negative correlation on the heatmap. The same negative correlation is observed between the presence of the promotion in the store and the day of a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b549cdb-9073-44e3-9e55-d3be73677bd0",
    "_uuid": "f5e39eb4242fc617470ff39f0b6fac8c661f575b"
   },
   "outputs": [],
   "source": [
    "# sale per customer trends\n",
    "sns.factorplot(data = train_store, x = 'DayOfWeek', y = \"Sales\", \n",
    "               col = 'Promo', \n",
    "               row = 'Promo2',\n",
    "               hue = 'Promo2',\n",
    "               palette = 'RdPu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34c53db4-e4d8-46e5-8685-ff3bab810b9a",
    "_uuid": "cac5c896dbbfc0554a61076d6744cc2ebfdfc098"
   },
   "source": [
    "##### There are several things here:\n",
    "- In case of no promotion, both `Promo` and `Promo2` are equal to 0, `Sales` tend to peak on Sunday (!). Though we should note that `StoreType` C doesn't work on Sundays. So it is mainly data from `StoreType` A, B and D.\n",
    "- On the contrary, stores that run the promotion tend to make most of the `Sales` on Monday. This fact could be a good indicator for Rossmann marketing campaigns. The same trend follow the stores which have both promotion at the same time (`Promo` and `Promo2` are equal to 1).\n",
    "- `Promo2` alone doesn't seem to be correlated to any significant change in the `Sales` amount. This can be also prooved by the blue pale area on the heatmap above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5dc423b7-0569-4805-b93b-8abeaa2fd923",
    "_uuid": "c8548ebedc38bf7f36f5f22cd92f652cd83b7748"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "92029a40-d511-4bc4-9e0a-c2844066a237",
    "_uuid": "a627f9e2193305842b2ae6d78ba253b451f1d26f"
   },
   "source": [
    "### Conclusion of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "52c64199-9af5-44dc-a9bd-a4615f9aabd7",
    "_uuid": "83d9bce576100392312554c561372e22eed98478"
   },
   "source": [
    "- The most selling and crowded `StoreType` is A.\n",
    "\n",
    "\n",
    "- The best \"Sale per Customer\" `StoreType` D indicates to the higher Buyer Cart. To benefit from this fact, Rossmann can consider proposing bigger variety of its products.\n",
    "\n",
    "\n",
    "- Low `SalePerCustomer` amount for `StoreType` B indicates to the possible fact that people shop there essentially for \"small\" things. Eventhough this `StoreType` generated the least amount of sales and customers over the whole period, it shows a great potential.\n",
    "\n",
    "\n",
    "- Customers tends to buy more on Modays when there's one promotion (`Promo`) and on Sundays when there's no promotion at all (both `Promo` and `Promo1` are equal to 0).\n",
    "\n",
    "\n",
    "- Promo2 alone doesn't seem to be correlated to any significant change in the `Sales` amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ace8c30e-7bcf-4b25-9054-6128abe18254",
    "_uuid": "5409f2079ca6dc3b52ca87d140f0616f70ddfc77"
   },
   "source": [
    "<br>\n",
    "## Time-Series Analysis per Store Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4718aa67-1bf7-4a9c-9ebf-652d3e0a2781",
    "_uuid": "d40a766bed18a78c1b111189a76602df80756277"
   },
   "source": [
    "What makes a time series different from a regular regression problem? \n",
    "\n",
    "- It is time dependent. The basic assumption of a linear regression that the observations are independent doesn’t hold in this case.\n",
    "- Along with an increasing or decreasing trend, most time series have some form of seasonality trends, i.e. variations specific to a particular time frame. For example, for Christmas holidays, which we will see in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "449f5d38-7e71-4dea-92cf-65ca8f303815",
    "_uuid": "804c4c36a2b46f14ecb9f899aaa56d50adb03f43"
   },
   "source": [
    "We build a time series analysis on store types instead of individual stores. The main advantage of this approach is its simplicity of presentation and overall account for different trends and seasonalities in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "137a404c-aaa6-4ec7-8fbd-6100b1bad7e7",
    "_uuid": "abac6543ac6a34643f54733d5201bddcc5f1ff28"
   },
   "source": [
    "In this section, we will analyse time series data: its trends, sesonalities and autocorrelation. Usually at the end of the analysis, we are able to develop a seasonal ARIMA (Autoregression Integrated Moving Average) model but it won't be our main focus today. Instead, we try to understand the data, and only later come up with the forecasts using Prophet methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de7a8aca-dd58-43c4-8520-2e4dfe436b38",
    "_uuid": "03a62c8f7efec05278f00e03247b41a865470867"
   },
   "source": [
    "### Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "29490a90-37c7-4ee4-b470-71e96b33a81c",
    "_uuid": "33b6a80dcc90d0f57826f644d2dd0774203c6359"
   },
   "source": [
    "##### We take four stores from store types to represent their group:\n",
    "- Store number 2 for `StoreType` A\n",
    "- Store number 85 for `StoreType` B, \n",
    "- Store number 1 for `StoreType` C \n",
    "- Store number 13 for `StoreType` D. \n",
    "\n",
    "It also makes sense to downsample the data from days to weeks using the `resample` method to see the present trends more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2410d7f1-8f83-42a7-9641-119f4a6ba45e",
    "_uuid": "e37d97e5918982442e141bd647b1f6041065e90a"
   },
   "outputs": [],
   "source": [
    "# preparation: input should be float type\n",
    "train['Sales'] = train['Sales'] * 1.0\n",
    "\n",
    "# store types\n",
    "sales_a = train[train.Store == 2]['Sales']\n",
    "sales_b = train[train.Store == 85]['Sales'].sort_index(ascending = True) # solve the reverse order\n",
    "sales_c = train[train.Store == 1]['Sales']\n",
    "sales_d = train[train.Store == 13]['Sales']\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 13))\n",
    "\n",
    "# store types\n",
    "sales_a.resample('W').sum().plot(color = c, ax = ax1)\n",
    "sales_b.resample('W').sum().plot(color = c, ax = ax2)\n",
    "sales_c.resample('W').sum().plot(color = c, ax = ax3)\n",
    "sales_d.resample('W').sum().plot(color = c, ax = ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19808aac-1687-4be1-9ed1-a66a766ec577",
    "_uuid": "e1b5c51ff08c4db00d40b95f6d42f0ac8128ca04"
   },
   "source": [
    "Retail sales for `StoreType` A and C tend to peak for the Christmas season and then decline after the holidays. We might have seen the same trend for `StoreType` D (at the bottom) but there is no information from July 2014 to January 2015 about these stores as they were closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a009654-9d9f-4de8-915b-1739f6d7da2f",
    "_uuid": "9977e3db623314e191be33aa1fea3a355acb4cbe"
   },
   "source": [
    "### Yearly trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "efc27857-abb6-4d70-8002-d7b0b652761d",
    "_uuid": "11848efdae6e532084b784b4023fc142ea799c4e"
   },
   "source": [
    "The next thing to check the presence of a trend in series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "622f9853-dcd9-411f-b02d-f27f7f483d78",
    "_uuid": "31cbcd812ed45fd194216dc530ad793b7667089f"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 13))\n",
    "\n",
    "# monthly\n",
    "decomposition_a = seasonal_decompose(sales_a, model = 'additive', freq = 365)\n",
    "decomposition_a.trend.plot(color = c, ax = ax1)\n",
    "\n",
    "decomposition_b = seasonal_decompose(sales_b, model = 'additive', freq = 365)\n",
    "decomposition_b.trend.plot(color = c, ax = ax2)\n",
    "\n",
    "decomposition_c = seasonal_decompose(sales_c, model = 'additive', freq = 365)\n",
    "decomposition_c.trend.plot(color = c, ax = ax3)\n",
    "\n",
    "decomposition_d = seasonal_decompose(sales_d, model = 'additive', freq = 365)\n",
    "decomposition_d.trend.plot(color = c, ax = ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6c2a0d9-ecc0-4428-b9ed-5cb59825eec6",
    "_uuid": "ab965f7ef8da78e31c7c582bc7d05cf129fe200c"
   },
   "source": [
    "Overall sales seems to increase, however not for the `StoreType` C (a third from the top). Eventhough the `StoreType` A is the most selling store type in the dataset, it seems that it cab follow the same decresing trajectory as `StoreType` C did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19a39a9a-94bd-426f-b368-ee3174bb9f23",
    "_uuid": "f5f9c4d5c110d7bf77a4eb39936d7e4dc3551cfb"
   },
   "source": [
    "### Autocorrelaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6484122c-8ca7-4163-bcbd-e5acd61d5596",
    "_uuid": "ffa9084c0d919ccf4ad7fe908f96981d48128a3b"
   },
   "source": [
    "The next step in ourtime series analysis is to review Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots. \n",
    "\n",
    "ACF is a measure of the correlation between the timeseries with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’tn’ with series at instant ‘t1-5’…’tn-5’ (t1-5 and tn being end points).\n",
    "\n",
    "PACF, on the other hand, measures the correlation between the timeseries with a lagged version of itself but after eliminating the variations explained by the intervening comparisons. Eg. at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac47d973-e835-499e-81c1-5f94de91fca9",
    "_uuid": "5b37785066879f7f5b190e451721e0ad4dbeb55d"
   },
   "outputs": [],
   "source": [
    "# figure for subplots\n",
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "# acf and pacf for A\n",
    "plt.subplot(421); plot_acf(sales_a, lags = 50, ax = plt.gca(), color = c)\n",
    "plt.subplot(422); plot_pacf(sales_a, lags = 50, ax = plt.gca(), color = c)\n",
    "\n",
    "# acf and pacf for B\n",
    "plt.subplot(423); plot_acf(sales_b, lags = 50, ax = plt.gca(), color = c)\n",
    "plt.subplot(424); plot_pacf(sales_b, lags = 50, ax = plt.gca(), color = c)\n",
    "\n",
    "# acf and pacf for C\n",
    "plt.subplot(425); plot_acf(sales_c, lags = 50, ax = plt.gca(), color = c)\n",
    "plt.subplot(426); plot_pacf(sales_c, lags = 50, ax = plt.gca(), color = c)\n",
    "\n",
    "# acf and pacf for D\n",
    "plt.subplot(427); plot_acf(sales_d, lags = 50, ax = plt.gca(), color = c)\n",
    "plt.subplot(428); plot_pacf(sales_d, lags = 50, ax = plt.gca(), color = c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "18512b29-7966-4f96-9f5d-ea7d67ce9148",
    "_uuid": "523825025c9f8875292094f6748a46c6a0b2249e"
   },
   "source": [
    "We can read these plots horizontally. Each horizontal pair is for one 'StoreType', from A to D. In general, those plots are showing the correlation of the series with itself, lagged by x time units correlation of the series with itself, lagged by x time units.\n",
    "\n",
    "There is at two things common for each pair of plots: non randomnes of the time series and high lag-1 (which will probably need a higher order of differencing d/D).\n",
    "\n",
    "- Type A and type B:\n",
    "Both types show seasonalities at certain lags. For type A, it is each 12th observation with positives spikes at the 12 (s) and 24(2s) lags and so on. For type B it's a weekly trend with positives spikes at the 7(s), 14(2s), 21(3s) and 28(4s) lags. \n",
    "\n",
    "\n",
    "- Type C and type D:\n",
    "Plots of these two types are more complex. It seems like each observation is coorrelated to its adjacent observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa5ee8f1-3b65-4338-9e39-d1cda1ef811e",
    "_uuid": "b8bf410fb049e377123c7eaa3305a842911997aa"
   },
   "source": [
    "## Time Series Analysis and Forecasting with Prophet\n",
    "#### Forecasting for the next 6 weeks for the first store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c04d2f6-bd8f-45e2-b85e-791f7b1ade2a",
    "_uuid": "2f6dca745c7dcedf3a3567c0365deaa06d78a389"
   },
   "source": [
    "The Core Data Science team at Facebook recently published a new procedure for forecasting time series data called [Prophet](https://research.fb.com/prophet-forecasting-at-scale/). It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It enables performing [automated forecasting which are already implemented in R](https://www.rdocumentation.org/packages/forecast/versions/7.3/topics/auto.arima) at scale in Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d8d98e16-447d-4590-a3e6-05fa3f59417a",
    "_uuid": "c7dfa8eaa64ccdf03e4ff9501799eec497ebbcb2"
   },
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = pd.read_csv(\"../input/train.csv\",  \n",
    "                    low_memory = False)\n",
    "\n",
    "# remove closed stores and those with no sales\n",
    "df = df[(df[\"Open\"] != 0) & (df['Sales'] != 0)]\n",
    "\n",
    "# sales for the store number 1 (StoreType C)\n",
    "sales = df[df.Store == 1].loc[:, ['Date', 'Sales']]\n",
    "\n",
    "# reverse to the order: from 2013 to 2015\n",
    "sales = sales.sort_index(ascending = False)\n",
    "\n",
    "# to datetime64\n",
    "sales['Date'] = pd.DatetimeIndex(sales['Date'])\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39c9d9a3-8036-4ce6-a1ee-c696cb2e3b90",
    "_uuid": "efd3d7a8e97fe2c1998e4e590de58802b07dcf7e"
   },
   "outputs": [],
   "source": [
    "# from the prophet documentation every variables should have specific names\n",
    "sales = sales.rename(columns = {'Date': 'ds',\n",
    "                                'Sales': 'y'})\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2b15a8a-c7be-4135-a8c2-3f6f0b28ba41",
    "_uuid": "fd790644cbd4c52ff936811cfa729b92a2c208ed"
   },
   "outputs": [],
   "source": [
    "# plot daily sales\n",
    "ax = sales.set_index('ds').plot(figsize = (12, 4), color = c)\n",
    "ax.set_ylabel('Daily Number of Sales')\n",
    "ax.set_xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3595dde-c625-4412-a242-08030b3d10e0",
    "_uuid": "181e060488627fb055399998a50f759538ecb441"
   },
   "source": [
    "### Modeling Holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6b49863-b009-4e68-a4c9-916f1fc56739",
    "_uuid": "d99df9e8487b8feff43d940fc8d436f2c236b501"
   },
   "source": [
    "Prophet also allows to [model for holidays](https://facebookincubator.github.io/prophet/docs/holiday_effects.html), and that's what we do here.\n",
    "\n",
    "The StateHoliday variable in the dataset indicates a state holiday, at which all stores are normally closed. There are also school holidays in the dataset at which ceratin stores are also closing their doors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "418c4d33-08f3-484e-9ff1-79b00b19310a",
    "_uuid": "4125c9ab0bc590b7050424c6e019003f85a634f9"
   },
   "outputs": [],
   "source": [
    "# create holidays dataframe\n",
    "state_dates = df[(df.StateHoliday == 'a') | (df.StateHoliday == 'b') & (df.StateHoliday == 'c')].loc[:, 'Date'].values\n",
    "school_dates = df[df.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "\n",
    "state = pd.DataFrame({'holiday': 'state_holiday',\n",
    "                      'ds': pd.to_datetime(state_dates)})\n",
    "school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                      'ds': pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = pd.concat((state, school))      \n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "796c0e2a-c659-4c18-991c-2b209a767ee4",
    "_uuid": "ec11e1fcbb72d098a8e8c28657888243746f3fcf"
   },
   "outputs": [],
   "source": [
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(interval_width = 0.95, \n",
    "                   holidays = holidays)\n",
    "my_model.fit(sales)\n",
    "\n",
    "# dataframe that extends into future 6 weeks \n",
    "future_dates = my_model.make_future_dataframe(periods = 6*7)\n",
    "\n",
    "print(\"First week to forecast.\")\n",
    "future_dates.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10fd6159-7dbe-44cf-87d5-e329eb5a58e2",
    "_uuid": "003bccbae7c43979f072e63b680739af28809787"
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "forecast = my_model.predict(future_dates)\n",
    "\n",
    "# preditions for last week\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7702a93-c542-453b-b1ef-c780f7a6578e",
    "_uuid": "7485d14e593ca99bca724014611c67812acb37bf"
   },
   "source": [
    "The forecast object here is a new dataframe that includes a column yhat with the forecast, as well as columns for components and uncertainty intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a2432f9-9bd7-4b36-9141-43447c4ca448",
    "_uuid": "ee3bd97dd2ebcd301fd09e6c78077e0b803ed208",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = forecast[['ds', 'yhat']].rename(columns = {'Date': 'ds', 'Forecast': 'yhat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "300e9a3a-bf0d-43e4-aac3-e9db12f2c500",
    "_uuid": "58c59894209b070ed5ac8b3d1369bbf76cd265ee"
   },
   "source": [
    "Prophet plots the observed values of our time series (the black dots), the forecasted values (blue line) and the uncertainty intervals of our forecasts (the blue shaded regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0de56903-5ab2-45d4-99b0-10ba497006b9",
    "_uuid": "c2b553f8d2b69ee465b8f2a34a9e90182d258daa"
   },
   "outputs": [],
   "source": [
    "# visualizing predicions\n",
    "my_model.plot(forecast);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48185ddd-8f02-4e11-a140-346e6e6c5552",
    "_uuid": "199a605832653b53d21be752fb70d94571167bb7"
   },
   "source": [
    "As we see Prophet catches the trends and most of the time gets future values right.\n",
    "\n",
    "One other particularly strong feature of Prophet is its ability to return the components of our forecasts. This can help reveal how daily, weekly and yearly patterns of the time series plus manyally included holidayes contribute to the overall forecasted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26fded30-65b3-425f-9bc0-695fd2e51742",
    "_uuid": "ebb2326cfd275eb2dc26d2a191dfe7935ac59cfa"
   },
   "outputs": [],
   "source": [
    "my_model.plot_components(forecast);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93d3d3aa-d0f6-4be3-8897-63242cd6db67",
    "_uuid": "dd7c1221d2de07fd847da4ab4dea28ec57fee9c1"
   },
   "source": [
    "The first plot shows that the monthly sales of store number 1 has been linearly decreasing  over time and the second shows the holiays gaps included in the model. The third plot highlights the fact that the weekly volume of last week sales peaks towards the Monday of the next week, while the forth plot shows that the most buzy season occurs during the Christmas holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8b237378-130a-4c83-8fff-f33904b441b5",
    "_uuid": "2e2fedfeb67d98f7a38f29725a1640fccc21dd6e"
   },
   "source": [
    "### Conclusion of Time Series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e70ba3c4-62cf-4070-b821-ef6d4a919f64",
    "_uuid": "032d12f318ea0dcfd985f3474087ece16c3e9c8c"
   },
   "source": [
    "During this part, we discussed time series analysis with `.seasonal_decompose()`, `ACF` and `PCF` plots and fitted forecasting model using a new procedure by Facebook `Prophet`.\n",
    "\n",
    "We can now present main advantages and drawbacks of time series forecasting:\n",
    "\n",
    "##### __Advantages__\n",
    "- A powerful tool for the time series forecasting as it accounts for time dependencies, seasonalities and holidays (Prophet: manually).\n",
    "- Easily implemented with R `auto.arima()` from `forecast` package, which runs a complex grid search and sophisticated algorithm behind the scene.\n",
    "\n",
    "##### __Drawbacks__\n",
    "- Doesn't catch interactions between external features, which could improve the forecasting power of a model. In our case, these variables are `Promo` and `CompetitionOpen`. \n",
    "- Even though Prophet offers an automated solution for ARIMA, this methodology is under development and not completely stable.\n",
    "- Fitting seasonal ARIMA model needs 4 to 5 whole seasons in the dataset, which can be the biggest drawback for new companies.\n",
    "- Seasonal ARIMA in Python has 7 hyper parameters which can be tuned only manually affecting significantly the speed of the forecasting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ebea717-4d41-45bb-83be-d1a0ad31ab2d",
    "_execution_state": "idle",
    "_uuid": "4fe85fa76965083814a90beabd36ad07266be574"
   },
   "source": [
    "**Want to see more of Kernels like this one? Leave an upvote then :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
